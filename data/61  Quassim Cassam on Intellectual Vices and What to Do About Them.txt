
All of us have been wrong about things from time to time. But sometimes it was a simple, forgivable mistake, while other times we really should have been correct. Properties that systematically prevent us from being correct, and for which we can legitimately be blamed, are “intellectual vices.” Examples might include closed-mindedness, wishful thinking, overconfidence, selective attention, and so on. Quassim Cassam is a philosopher who studies knowledge in various forms, and who has recently written a book Vices of the Mind: From the Intellectual to the Political. We talk about the nature of intellectual vices, how they manifest in people and in organizations, and what we can possibly do to correct them in ourselves.

Support Mindscape on Patreon.
Quassim Cassam received his Ph.D. in philosophy from Oxford University. He is currently Professor of Philosophy at the University of Warwick. He previously held faculty positions at Cambridge University and University College London. He has served as the president of the Aristotelian Society, and was awarded a Leadership Fellowship by the Arts and Humanities Research Council in the UK.
Web pagePhilPeople profileWikipediaAmazon.com author pageSelf-Knowlege for Humans web siteTwitter


				Click to Show Episode Transcript			

			Click above to close.  All of us have been wrong about things from time to time. But sometimes it was a simple, forgivable mistake, while other times we really should have been correct. Properties that systematically prevent us from being correct, and for which we can legitimately be blamed, are “intellectual vices.” Examples might include closed-mindedness, wishful thinking, overconfidence, selective attention, and so on. Quassim Cassam is a philosopher who studies knowledge in various forms, and who has recently written a book Vices of the Mind: From the Intellectual to the Political. We talk about the nature of intellectual vices, how they manifest in people and in organizations, and what we can possibly do to correct them in ourselves. Support Mindscape on Patreon. Quassim Cassam received his Ph.D. in philosophy from Oxford University. He is currently Professor of Philosophy at the University of Warwick. He previously held faculty positions at Cambridge University and University College London. He has served as the president of the Aristotelian Society, and was awarded a Leadership Fellowship by the Arts and Humanities Research Council in the UK. 
				Click to Show Episode Transcript			 0:00:00 Sean Carroll: Hello, everyone, welcome to the Mindscape Podcast. I’m your host, Sean Carroll. And if you’re anything like me, you’re surrounded by other people who are wrong about all sorts of important things. Now, of course, people can be wrong for all sorts of different reasons, right? I mean, maybe they’re just not that smart. Maybe they just end up being not quite clever enough to get the right answer. Or maybe they’re just not informed, to be a little bit less judgmental about it. Maybe they don’t have the right background, the right information to reach correct conclusions. But there’s other people who you no doubt notice seem to be really smart and yet keep getting things wrong or at least get something wrong in a really, really important way. And in some sense it’s their fault, right? If someone is just uninformed, you don’t blame them for being wrong unless you blame them for being uninformed. But you could just say, well, they didn’t know any better. 0:00:53 SC: But there’s cases out there where you recognize that people really should know better and there’s something about that person that is preventing them from being correct. My guest today is Quassim Cassam. He is a philosopher at the University of Warwick in the UK and he’s written a book on intellectual vices. The book is called Vices of the Mind: From the Intellectual to the Political. And the point of the word vice here is that this is something that is preventing you from getting the right answer in a blame-worthy way. 0:01:26 SC: We’ve all talked about cognitive biases or other things like that. Sometimes, the cognitive bias can be an intellectual vice, but other times it’s sort of inevitable. So, it’s a slightly different kind of category. Cassam is talking about all the different ways in which people get things wrong in important but in principal correctable ways, ways that we can really blame them for getting wrong. And, of course, we can go on about the current political situation and wonder whether or not the people we disagree with are subject to these intellectual vices. One way or the other, I think that the important thing here, from my perspective, is we all have these vices ourselves. There should be some way to get better at it. So, we talk a little bit about where these vices come from, why they exist, why it is worth blaming someone for being wrong in these different ways, and then of course, how we ourselves can be better at it. 0:02:19 SC: I wanna remind you that we have a website for the podcast preposterousuniverse.com/podcast. On the website, for every different post, for every different episode of Mindscape, you can find not only links to the people’s stuff but you can also find a full transcript of every episode. There’s also a Patreon page linked to from the website. And if you’re wondering why there’s a Patreon even though there are ads on the podcast now, you can get an ad-free version of the podcast if you subscribe and support on Patreon as well as monthly Ask Me Anything episode. So, there are still reasons to be a Patreon supporter as well as, of course, my undying gratitude. With that, let’s go. [music] 0:03:16 SC: Quassim Cassam, welcome to the Mindscape Podcast. 0:03:18 Quassim Cassam: Hello there, Sean. It’s good to be here. 0:03:21 SC: Now, you’re a professional philosopher, an epistemologist, I think it’s safe to say. And I know a little bit about epistemology, not that much. My experience with epistemology is that it’s a somewhat dry field. People are talking about the sense data we collect, how to verify propositions and things like that. But you’re involved in a project, in particular, with what you call intellectual vices that seems a lot more grounded down to earth related to psychology and how people live and talk in the world. So, why don’t you give us a little bit of background on epistemology generally and then how your project fits into that?  0:03:57 QC: Yeah. So, epistemology, I think, can often be a very dry field. So, epistemology is the philosophical study of knowledge. So, there’s lots of questions that epistemologists typically ask. Questions like what is it to know something? What are the sources of human knowledge? Questions like that. So, these are very abstract high-level general questions. And although epistemologists usually use examples to illustrate their points and their claims, the examples they use tend to be rather kind contrived made-up examples that are designed to make the point they want to make. So, I have to confess that a lot of my own work in the past has been a bit like that. But in the last few years I’ve become quite interested in seeing how to apply epistemology, the philosophical insights about the nature of knowledge, to the real world problems, to real world issues and particularly political questions and political issues. 0:05:01 QC: There’s a kind of branch of epistemology now which people call political epistemology. And, I guess, that’s really what I’m doing. Political epistemology is an attempt to connect epistemology with questions about how politics works and how it doesn’t work. And that really was the kind of inspiration for my book. And I say at the beginning that I was really motivated to write the book by the way politics seemed to be going both in the UK and in the US, particularly in 2016 with major events on both sides of the Atlantic, and before that, the Iraq war. I have kind of discussions of all of those subjects in my book. And I try to account for them using this notion which you mentioned, the notion of an intellectual or an epistemic vice. And, I guess, I should say more about that if you’d like me to. 0:06:01 SC: Well, yeah. I mean, I think that I personally, and I hope that Mindscape listeners are very familiar with ideas like cognitive biases or ways in which we can be irrational, but this is slightly different slant. It’s closely related. It’s in the same neighborhood, but a vice seems much more normative, much more judgmental. So, yeah, tell us what an intellectual vice is. 0:06:22 QC: Yeah. So, one thing that maybe distinguishes vices, intellectual vices, and indeed even moral vices from cognitive biases is that vices are clearly personal qualities. So, vices are personal characteristics that one person may have and another person may not have. So, some people, let’s say, are close-minded and others are not. Arrogance is a characteristic that some people have and others don’t. Maybe wishful thinking is something that some people are more prone to than others, and so on. 0:06:57 QC: That’s one difference, because certainly when people talk about cognitive biases, I think they tend to think of them as universal more or less, and in many cases is operating not at the level of the person, but at the level of their brains and the way their brains process information. So that’s the first thing to say about the notion of a vice. Now, these personal qualities can take many different forms, so some vices, I want to say, take the form of character traits, so close-mindedness you might think of as a character trait, or there are vices that take the form of ways of thinking, like wishful thinking, and then there are vices that take the form of attitudes. So for example, you might think of prejudice as an attitude and as an intellectual vice. So that’s the next thing to say about these vices. But the really big point is this, a vice [0:07:51] ____ is things kind of bad, that’s the basic notion of a vice. 0:07:56 QC: So, virtues are good personal qualities to have and vice is a bad personal qualities to have. So traditionally, of course, people thought very much about moral virtues and vices in this connection. So classically, courage was seen as a moral virtue and cowardice as a moral vice. So intellectual vices and virtues are intellectual qualities that people have, which are either good for them to have that contribute to their intellectual flourishing, or bad qualities for them to have, and those are the intellectual vices. And just this again, I think relates to your question about cognitive biases that… So when people talk about virtues and vices, I think there’s a really strong intuition that your virtues and vices are things for which you can be praised or blamed, or criticized or admired. 0:08:55 QC: So the virtues are supposed to be kind of admirable personal qualities, qualities for which you might reasonably be praised, and vices are the opposite, they’re dis admirable qualities. And that again is a difference with at least some cognitive biases, where it’s not so clear that notions are praise and blame, so, there you have the story. So there are personal qualities, there are intellectual qualities in the case of vices, there are personal intellectual qualities that are in some sense bad for us, intellectually speaking. And lastly, there are personal qualities for which we can be blamed or criticized. So that’s the basic notion of an intellectual vice. 0:09:42 SC: Right? And this discussion begs the question of whether or not it’s… Or under what circumstances is it okay to blame somebody or give them responsibility? There’s sort of a free will volition kind of issue that comes in here. Do we imagine that vices are things that people could choose to change if they wanted to, or at least that they could try to change them?  0:10:04 QC: Yeah, so that’s a really fundamental question about virtues and vices. So you’re absolutely right, so if you’re gonna talk about blame particularly, then it seems as though you have to think that vices are things that people are responsible for. And then if you think people are responsible for them, then it looks as though they need to have some kind of control over them. And then people worry that we don’t really have control of our own character traits, so how can we be blamed for them? So I think the discussion of this issue is a really complicated, right? So one thing I would wanna say is that, with respect to at least some vices, I don’t think that control is a really big issue. If you think of vices that take the form of attitudes, to say that we have control over them is to say that it’s possible for us to change or alter our attitudes, and indeed I think it is possible in at least some cases. 0:11:02 QC: Similarly, it’s possible to change at least to some extent, the way we think. The hardest case is character traits where it’s much more tempting to think of them as completely fixed and unalterable. I’m not sure I really buy that, I think that we, again, are not completely victims of our own character, and that there is some possibility of revision. The question really is, how easy is it for us to revise our character traits or our attitudes or our thinking styles? So that’s one cluster of issues. But I just wanna give you an example which maybe is helpful. So this is an example suggested by a philosopher called Heather Battaly. So imagine a young man in an area of Pakistan who is brought up in a Taliban control village, and because of the way this guy has been brought up, he has all sorts of prejudices, say prejudices against women, for example. So he thinks that women should not be allowed out of the house unless accompanied by an adult male relative. 0:12:15 QC: Now, of course, if you ask, “Well, why does this person think this, and what kind of control does this person have over this attitude of his?” So the natural thing to think is, well, he thinks these things not because they’re true and I guess they aren’t true, but he thinks these things because of his circumstances and his upbringing and the community and culture which he lives in. And then to say, “Well he has control over these things.” Seems implausible, because you might wanna say, “Well how can he change those things?” But I think it is worth noting in this case, that whatever we think about the issue of control or change, I don’t think he is completely off the hook. I mean, it seems to me that it would be all to say that he’s straightforwardly blameworthy for his attitudes, maybe blame isn’t quite the right notion here. 0:13:09 QC: But nevertheless, I think it’s perfectly reasonable to criticize his attitudes, right? I mean these are really bad attitudes to have, and I think criticism is completely appropriate in these cases. And then, of course, the question is, “Well, are you criticizing his attitudes or are you criticizing him?” Right, so maybe there’s some scope for saying, “Well, no doubt he has terrible attitudes, and we… ” Its okay to criticizes his attitudes but that person being criticized is him but beyond a certain point is quite hard to sustain the distinction between a person’s attitudes and the person because you might think a person is in some sense made up of his attitudes and character traits and so on. 0:13:46 SC: It seems that the discussion presumes that there is some shared or maybe even universal objective kind of goal that we have when being epistemologists or when trying to think about the world that we all want truth and it’s probably an easier discussion to have when we’re talking about scientific or physical natural facts about the world than about moral stances and so is that a fair thing to say, that we can only have this discussion about what’s an intellectual vice if we agree that we all want to get things right at the end of the day and we more or less agree on what it would mean to get things right?  0:14:26 QC: Yeah, I suppose that’s fair enough, I guess that rather than talking about truth I think I’d wanna say that what we want and need as human beings is knowledge of the world around us that’s something we actually need just to survive and just to get by. And the other thing that we look for is understanding, it’s not just a matter of knowing that certain propositions are true but we also want to understand why they’re true or how they’re true and how they fit in with other things that we know. 0:14:57 QC: So now, of course if somebody says, well look, there’s no such thing as knowledge or there’s no such thing as truth then you’re quite right, that ends the discussion although I’d wanna probe them a bit more about why they think these things but I think for most people and hopefully for most people listening to this podcast we do think that it’s possible for us to know some of the things and that there are personal qualities that make it easier for us to know things about the world around us and personal qualities that make it much more difficult to have knowledge or understanding of the world around us. So the vices are then these personal qualities that get in the way of our ability to know or understand the world around us, and if somebody were to say to me in all seriousness yeah, well, that’s fine but who cares about knowledge or understanding, I think I’d be inclined to think that they’re not really being serious, that’s the kind of provocative remark that people make for the sake of argument but I don’t think it’s a very sensible thing to say. 0:16:05 QC: Supposing you have a young child and you are considering whether to give the child vaccinations recommended by your doctor, I guess you really wanna know what’s the right thing to do that’s a very pressing practical question for you and if somebody were to say, yeah but look who cares about knowledge? We don’t need to worry about knowing whether this is the right thing to do or not for your child, I just don’t think that’s what anyone seriously believes and the same goes for each of us in our own lives, you want to know things and if you don’t want to know things, you’re not really gonna get very far in your life. Now wanting isn’t enough you need to have the intellectual resources to actually know stuff and these intellectual resources are gonna include personal qualities that either make it easier or more difficult for you to know. 0:17:06 SC: Let’s just home in exactly on this difference between intellectual vice and a cognitive bias, on the one hand the vice is something you can be blamed for on the other hand the bias might be deeper ingrained and you can’t help it, in fact in some sense vices could even be useful in thinking fast kind of way, there’s shortcut heuristic that get us to places but they overlap at the same time. Maybe some examples of one versus the other would help people clear things up. 0:17:40 QC: Yeah, so a good example is something like confirmation bias, so confirmation bias is something that I think we all suffer from, the tendency to look for information that supports what we already believe and the corresponding tendency to ignore evidence that goes the other way so confirmation bias I suppose you can certainly imagine circumstances in which confirmation bias isn’t necessarily gonna be bad for you if what you already believe is true then confirmation bias isn’t gonna get in the way of your grasp for the truth it’s just gonna strengthen your already true beliefs. But maybe this goes back to the thing you were saying about traditionally epistemology, one thing that traditionally epistemology has always thought I think, and I think this is true is it knowing isn’t just a matter of having beliefs that are true, knowing also involves having beliefs which you are justified in having and so there’s some sense in which knowledge requires justified beliefs, beliefs based on for example, evidence or good reasoning or solid information. 0:19:04 QC: So in the case of confirmation bias, if a particular belief of yours is sustained by this bias by kind of unthinking confirmation bias even if that belief of yours happens to be true and even if you are confirmed in that true belief by your bias it’s still gonna be problematic because there’s still not going to be the case that your belief is justified if it is really sustained by a cognitive bias and nothing else. Having said all that, I think it’s also… I think it’s perfectly true that the distinction between cognitive biases and intellectual vices isn’t a sharp one and there may be as you were suggesting there may be a kind of area where they shade into one another so I think there are these two things to think about, one is, is there a sharp distinction between the two and I would wanna say there isn’t a sharp distinction between the two but there is some distinction between the two. And the other thing is to think about the conditions for knowing and how knowing requires actually having beliefs that are justified not just beliefs that are true. 0:20:23 SC: You have some wonderful examples in the book. You did this wonderful thing where in every chapter, you begin with another egregious example of intellectual vices getting away. Well, let’s share some of those with the audience. A lot of them are quasi-political so that’s just the price we pay for this. But there are certainly examples in history where regardless of what you thought at the time should have happened in retrospect, people made mistakes. And you say that in some cases, we can attribute those mistakes to really, pretty severe intellectual vices. 0:20:57 QC: Yeah, yeah. So the example I start the book off with is the 2003 Iraq War. So with that example, I’m not really interested there in the question of whether the US was right or wrong to invade Iraq in 2003. That chapter’s more about whether, given that the US had decided or did decide to invade Iraq, what went wrong with the military preparations for the invasion? So clearly, I guess it’s relatively uncontroversial now that it all went horribly wrong. And it’s a really important practical question politically, militarily and in other ways to figure out how things went so badly wrong. Why was the US apparently so ill-prepared for this very complicated operation? Now, if you look back at the way the operation was planned and the attitudes of those planning it, one thing that I think you can see fairly clearly is considerable intellectual arrogance, the assumption by senior people in the then administration that they knew best. They knew what they were doing. They didn’t really have to listen to what the military planners were telling them. 0:22:21 QC: And that was the sort of arrogant, over-confident attitude that led to disaster. Over-confidence is another one, which I just mentioned. Over-confidence is a really powerful force in our lives. And when it comes to wars and military planning, it’s absolutely catastrophic. And I think that the over-confidence of the Bush administration, I think was a real problem in that case. So there are just two examples of intellectual vices that caused serious practical difficulties. Other people have other analyses and diagnoses of what went wrong but it’s fairly, it’s kinda interesting how many of these analyses really do talk about either intellectual vices or cognitive biases. Even if you think about the whole business about weapons of mass destruction, WMD, and the inquiry into whether Iraq did or didn’t have WMD, in retrospect of course, there was lots of talk about confirmation bias, the assumption that Iraq had WMD and then the tendency to interpret all evidence as supporting that assumption. 0:23:44 QC: Another thing that people talk about in this connection is groupthink, the tendency for a bunch of people to all, collectively as a group, all agree with one another and just move in a particular direction. So these are all, whether you wanna call them cognitive biases or whether you want to call them intellectual vices, these are all examples of, let’s call them intellectual defects or intellectual failings or intellectual flaws that had a major impact on the conduct of the war and had a major impact on the way war preparations were made. And then in later chapters, of course, I give other examples. There’s a chapter that’s dedicated to the Brexit vote in the UK and the whole issue of how that was argued for and how that was presented. So in that context, one issue is what people’s attitude was towards expert evidence about the consequences of the UK leaving the EU. And there are certainly plenty of examples which I quote in the book, of people basically saying, “We just don’t need to worry about what the experts tell us. We know how things are and we just don’t need to worry about the facts. There are the facts and then there are the facts that the expert tell us. But then, there are our facts, the alternative facts.” 0:25:19 QC: And that is an attitude which I think is deeply destructive as well and had destructive consequences in that debate. So here’s a kind of general question that people might wanna think about. If you’re thinking about political developments, politics in the last five or 10 years, can you think of particular political events or politicians or developments where the intellectual vices of some of the major actors played a big part in producing the political outcomes that we saw? I suspect that most listeners to this podcast won’t have much difficulty in thinking of examples of this thing. Clearly, which examples you come up with is rather gonna depend on what your politics are. I mean, I can imagine people on the Democratic side in the US immediately thinking of your current president when looking for examples to illustrate intellectual vices in action. But equally, I’m sure that people on the other side will have different examples. 0:26:34 SC: These examples are great because it highlights how what we’re talking about, forget about cognitive biases for a second but it’s not just foolishness or stupidity, or ignorance that we’re talking about here. It’s an active… You distinguished between attitudes, styles of thinking and character traits that actively get in the way of getting to the truth. And that it gives you, sort of, it gives people, I think, a handle on how the vices are special and that they could be improved ’cause it’s not just a lack of knowledge, it’s some way of thinking that you have that is actively obstructing you from getting to the truth. 0:27:14 QC: Yeah, so let me give you another example. So one of the chapters talks about the famous case of the 1973 Yom Kippur war. So this is something that’s been really extensively studied in Israel and elsewhere. So, just to remind people of the history. So, in 1973, Israeli intelligence was starting to receive multiple reports of military preparations by the Egyptians and Syrians, preparations that pointed to an impending attack by Egypt and Syria on Israel. Now, at that time the director of military intelligence in Israel was someone who was very strongly committed to the belief that the Arabs would not attack. I’m simplifying a bit but I think his view was that they would be crazy to attack and therefore that they wouldn’t attack. And therefore, that any evidence indicating that they were about to attack was not reliable, that all such evidence could simply be dismissed. 0:28:32 QC: So, well, what happened? Well, of course, what happened was that they did attack. So they attacked on Yom Kippur in that year, and because no serious preparations had been made on the Israeli side, the initial phase of that war went very badly for Israel. Eventually, they turned things around but, in fact, the Egyptians managed to cross the Suez Canal virtually unopposed at the outset. Now, if you’re thinking about, “Well what’s the vice here? That’s all very interesting but what’s the vice that we’re talking about?” Well, the vice that we’re talking about in that case is closed-mindedness. So this is a case of someone who… So we’re talking here about the head of military intelligence in Israel, someone who had arrived at a certain view, had as they say, frozen on a certain conception of what would and would not happen. 0:29:28 QC: So, he’d frozen on the idea that Israel would not be attacked at that time. Having fixed on that idea, his mind was really closed to all alternative perspectives. So, that’s really close-mindedness where you are simply not willing to give serious consideration to other points of view, to other perspectives. And it’s not just other points of view, it’s also not being willing to give serious consideration to actual concrete evidence, in this case intelligence that points the other way. Now, of course, we all know what happened. There was a real military price paid by Israel for that. Now, if you’re thinking about, “Well, what can we do about this? Can we do anything to guard against this?” Well, of course, the obvious thing is to put structures in place to make sure that people in these positions of power are really forced to consider alternative perspectives even if they’re not really inclined to. And open-mindedness can go too far but, nevertheless, it’s really important that people in these positions are seriously willing to engage with alternative perspectives. 0:30:48 QC: So that’s a case, that’s an example then… The example I gave is really an example of a particular intellectual vice, closed-mindedness. And if you think about what the impact of that vice was the impact was that it prevented… It prevented the director of military intelligence in Israel from knowing something that he would and could otherwise have known. He had all the evidence necessary to know that an attack was about to happen. He failed to know it. Why did he fail to know it? Because he ignored the evidence. Why did He ignore the evidence? Because he had already made up his mind and was closed-minded. And so, there you have a kind of explanation of a series, a series of events and that’s what I call a Vice expansion, an explanation of how things turned out that, in which the intellectual vices of one or more people is doing important explanatory work. And I don’t think that this explanation is particularly high-tech, I think it’s a perfectly common sensical explanation and it’s also interestingly an explanation that’s been given by people who studied what went wrong in that case, I’m not just making this up. 0:32:00 QC: There is actual evidence that this is actually what happened and there are quite a few references in the book to the relevant literature on this subject, and the whole… It’s rather odd that I keep coming back to military examples but these are examples where it’s just easier to see the point. Another case was the much older example, Operation Barbarossa, when the Nazis invaded the Soviet Union. Again, the Russians under Stalin had plenty of intelligence that the Nazis were about to attack. Stalin was convinced that they weren’t going to attack. And get this for close-mindedness. So, Stalin was so convinced that the Nazis were not going to attack that he had people who reported that they were going to attack, he had them shot. That’s closed-mindedness. 0:32:49 SC: But this is an excellent example to sort of dig into a little bit, the example of close-mindedness, because you sneaked in there the statement it’s possible to be too open-minded. And you have the case in your book of what about Holocaust denial where you say you’re not a super expert in the Holocaust, you know the basics, but you’re just not interested in spending your time reading the purported evidence from Holocaust denialists. So where exactly do we draw this line between being open-minded and close minded? Is there an objective way to do it or is it a more practical wisdom kind of thing?  0:33:26 QC: Yeah, I think it’s a very practical question. So let’s just go back to… Let’s just go back to Aristotle, that’s going back a long way. So lots of modern talk about virtues and vices originates in Aristotle. So Aristotle had this, I think, absolutely brilliant idea and I think it still is correct, which is that… With all these qualities that we’ve been talking about, it’s possible to have too much of something and it’s possible to have too little of something and it’s possible to have just the right amount of it. So the virtuous person who has neither too much nor too little. So the classic example is courage. So courage is a virtue. On the other side of courage is cowardice, where you have as it were too little courage. And then on the other side, on the opposite side, you have rashness, which is where you have as it were, an excess of courage. So, you have vices of excess, vices of deficiency, and then the virtue in the middle. 0:34:30 QC: So I think the same is true in the case of intellectual virtues and vices. So if you’re thinking about closed-mindedness as a vice, and open-mindedness as a virtue, so then the question is, so what would be the extreme? What would be the case where you are, as you were too open-minded? So that might be the vice of gullibility. So the open-minded person, the virtuous person is someone whose mind, of course, their mind has to be open to the extent of being willing to consider serious alternative options to what they think. So they need to not dismiss views just because they are at odds with their own views. But it’s also true that to function in the world as a Noah and as a someone with understanding, you have at some point got to take some questions as having been settled. 0:35:29 QC: And having reached that point, you don’t need to take seriously every single alternative perspective that’s proposed, however ill-founded that perspective is. So a question that I take to be settled is the question of the reality of the Holocaust. I take that to be overwhelming historical evidence that the Holocaust happened in just the way that we were all taught. Now, of course, there are Holocaust deniers. So Holocaust deniers say that, say things like Hitler didn’t know anything about it, or Hitler didn’t order it, or that very… Far fewer Jews were killed in the Holocaust than the 6 million figure that’s normally given, and so on, and so forth. Now if somebody were to say, “Well look, if you’re open-minded, surely you gotta take those claims seriously. Surely you’ve got to be willing to consider them.” 0:36:32 QC: I think my answer to that is, well, it depends on what you mean by “take those claims seriously”. I’m aware that those claims have been made, and I’m also aware that those claims have been refuted, they’ve been rebutted. And I’ve, in fact, speaking for myself, I have actually read some of those rebuttals and I found them kind of convincing. So having somebody saying to me, “Yeah, but look, it could still be true, couldn’t it?” And I wanna say, “Well, no.” In this case, there actually is evidence that settles the question. So I think when people talk about closed-mindedness, I think it’s a mistake to think that just because you think that certain questions have been settled, just because you think that the evidence does indeed point in one direction rather than another, that in itself makes you closed-minded. 0:37:22 QC: Open-mindedness, so the virtue of open-mindedness then it’s quite a kind of delicate matter to say what it involves and I guess in a way, the simplest way to put it would be to say, “Well, it’s neither an excess nor a deficiency.” And there’s no mathematical formula for that. 0:37:44 SC: Good. That’s exactly what I was gonna get at because I know in physics, among scientists, and among many philosophers and among me in my past life, there was this really strong desire for a mathematical formula, right? Like, if we were trying to say something deep and profound about either the world or wisdom or how to live our lives, there should be clear cut guidelines. And as I age into what is hopefully greater amounts of wisdom, I’m increasingly becoming impressed or fascinated by the idea that sometimes there just aren’t clear bright lines between these things and in morality it’s also something that comes up, you know, utilitarians can be thought of as people who want to find the formula for how we should act in all these different circumstances and I’m increasingly of the opinion that the formula doesn’t exist. Do you think that’s a healthy or a disastrous philosophical attitude?  0:38:39 QC: I think it’s an incredibly sensible attitude actually. And even when there is a formula, it’s not clear that you necessarily have to use it. Let me give you an example. So think about cooking. Now, of course there are recipes to cook, recipes that you can follow, that tell you exactly how much of each ingredient is required. Now, of course, it’s possible to follow those recipes, but I mean, one thing is that in the case of many recipes it actually doesn’t matter very much or matter at all if there are minor variations around the quantities that are given in the recipes. And of course, really, really good cooks don’t rely on recipes. They just have a feel for what’s the right amount of salt or what’s the right amount of chilly. 0:39:29 SC: Yeah. 0:39:30 QC: And I think that’s just life. That people with practical wisdom are people who just have just a kind of… I don’t know what to call it, a kind of instinctive sense of just what’s right and what’s wrong. And if you’re going… Supposing you’re going to a drinks party and you’re thinking, “Well, we don’t wanna stay too long. We don’t wanna to stay so long that the host get annoyed with us. But equally we don’t wanna leave too early because we don’t wanna be rude.” Right? So then you… Imagine saying to your partner, “Okay, so let’s figure this out. Exactly how many minutes do we need to stay for it to be the right number of minutes?” 0:40:10 QC: Now, that would be a kinda really stupid approach to this because of course, in reality, what happens if you’re sensible is that you go to the drinks party, and then depending on how things are going, you kind of have a feel for when it’s time to go. So you kinda, you realize that basically if you turn around and walk out of the door within 30 minutes, you’re probably gonna offend them, and you know equally that if you stick around until 3 o’clock in the morning, that’s probably also a really bad idea. So the good point, the good place, the good time to leave the party is gonna be some time between half an hour and 3:00 AM But there’s no formula for that. There’s no formula for that. It’s just that sensible people will actually kind of just be able to work it out. All right. And there’ll be a range, and leaving any time in that range is going to be basically fine. And I think that’s really these examples of the drinks party and the cook, I think they are very much in the spirit of what you’re suggesting about life, that the search for rigid formulae is just silly. I mean life isn’t… Mostly life just isn’t like that. [laughter] 0:41:20 SC: Like I said, I am moving in that direction where I try to be hard on myself and I try to avoid the intellectual vices here. I worry that it’s just a cop out that because I don’t know what the formula is, I deny that there is a formula. So I’m in between denying the existence of the formula and insisting that it must be there. 0:41:42 QC: Yeah, so what say… Okay. So let me ask you a question. So in the case of the drinks party, would you wanna say there’s a formula in that case?  0:41:50 SC: I think I get the example. It’s a very, very good one ’cause it’s very relatable. I can’t say it’s impossible that there’s a formula. I think that the way that you said it up is cheating a little bit because it sounded like we have to decide how many minutes ahead of time. But maybe there’s a formula that says, “Given the data we’re collecting while we’re there, given the eyebrows of the host and who’s sitting on the couch, there is a way to figure it out.” But on the other hand maybe not because I think that once we get into the realm of normativity and judgment, I think it’s not such a matter of it’s too hard, it’s just that the criteria themselves are fuzzy. 0:42:33 QC: Yeah. Judgment is absolutely the key word there. That so much is… So much is a matter of judgment. And I think that, actually, good judgment sounds like a very good candidate for being an intellectual virtue. And poor judgment is a very good candidate for being an intellectual vice. And if you think about people with bad judgement, you think about the lives they end up living. Mostly, it’s a terrible thing for them. Just on a personal level, leave aside intellectual matters, even on a personal level. Having bad judgment is something that has a real impact on us, and it’s something that we really want to need to avoid. And I think that’s a kind of illustration of a point I’m quite keen to emphasize in the book, which is that when we talk and talk about virtues and vices, although using labels like close-mindedness and dogmatism and so on, all of these are quite abstract labels. We’re not really talking here about something that’s purely abstract, we’re talking about stuff that actually makes an enormous practical difference in our day to day lives. 0:43:53 SC: Sure. 0:43:53 QC: And, of course, in the political world, in the military world, and in medical world. All of these things have consequences. They have real world impacts. And if you’re thinking about, “Well, why do you classify close-mindedness as a vice and why do you classify humility as a virtue?” Well, it’s got to be because you think that you’re gonna do better intellectually speaking and indeed, personally speaking with a bit of humility, than if you are close-minded. So we are talking here about something that’s philosophical, but also very practical. 0:44:36 SC: Is there some sort of grand unified theory of intellectual vices? Is there a single err vice from which everything else spills, or is it just a mishmash of different things that are preventing us from getting to the truth?  0:44:50 QC: Well, I think it’s more of a mishmash than they being a single grand theory. If you want a grand theory, then my offering in the book is what I call obstructivism. Obstructivism basically says that intellectual vices are personal qualities that systematically get in the way of knowledge and that we can be blamed or criticized for. So that’s your kind of uber theory of what an intellectual vice is. So because there’s so much focus on these vices getting in the way of knowledge, I tend to refer to them in the book as epistemic vices, but basically, it’s the same thing. So that’s your kind of general characterization. But then the question is, okay, so you’ve told me that there are personal qualities that get in the way of knowledge and that are kind of bad for it. But well, which qualities are these?  0:45:45 QC: Now, when you get to that level, then of course you start to think about, “Well, what are the different qualities that can have these impacts, and what unifies them, and how do we kind of classify them?” So I tend to be quite relaxed about this. In the book, I give, as I said earlier, examples of character traits, ways of thinking and attitudes that I wanna say are intellectual vices. But maybe there are other kinds of intellectual vice. I’m quite open about this. I don’t think we should be too rigid or too dogmatic about which… About the different kinds of vice that there are. But the important point is that they’ve got to be personal qualities that systematically get in the way of knowledge and/or understanding or if one prefers. And there’s got to be some room for blame or criticism. If somebody says, “Look, if this is a vice.” But of course, if somebody has his vice, you couldn’t possibly blame them or criticize the more indeed say anything but negative about them on account of this, then I wanna say, “Well then, it’s not a vice.” It is got to make sense to blame or criticize or negatively evaluate somebody if what they have is really a genuine intellectual vice. 0:47:12 SC: Could we imagine that things could be improved if there were an insistence on greater transparency about what people believed? I know that some people have gone so far as to suggest that everyone should make bets on what they think is true in some public forum or prediction markets. Is part of the problem with intellectual vice is that there’s not enough accountability for being wrong about these things?  0:47:38 QC: Well, I’m not sure that that’s the case. If you think about accountability, in the end the world turns out a certain way, and then it becomes apparent what the flaws were in your thinking. I mean, if you’re thinking about the Iraq war example. So take… This was a very controversial question in the run-up to the war. How many American troops would be needed to carry out a successful invasion of Iraq? So as I understand it, there were huge variations in the numbers there, that there were people in the military who thought that the number needed would be something like, I don’t know, 300,000 or something, like a really big number. And then there were people in the Bush Administration who thought that the number needed would be much smaller. You know, 40,000 or 50,000 or something like that. Now, if you were to say to these guys, “Okay, so I really wanna know what you really believe about this, okay? So put your money where your mouth is. How much are you willing to bet on this?” So maybe the people on the smaller number side said that we’re willing to bet a certain amount on the number being small and the people on the other side were willing to bet a certain amount on the number being large and maybe they were willing to bet the same amounts. Both sides believed with equal strength in what they were saying. 0:48:58 QC: But that in itself doesn’t really get us anywhere because then the question is, “Well, were the people who believed the number was really small, justified in believing that and whether the people who believed that the number was really big justified in believing that?” I mean, that’s the question. And that’s not a question about the strength of your belief or the strength of your conviction. It’s a question about whether you actually have good grounds for your beliefs. Now in that case, I mean, I would have said that even before the whole, even before we knew the outcome, that the people on the small number side of things were actually wrong, that they weren’t justified in believing what they said. And one reason they weren’t justified in believing it is that it went against expert military advice, the people who were defending the large number were actually, tended to be professional soldiers and the people defending the small number tended to be professional politicians. 0:49:50 QC: And given the choice between believing a professional soldier and a professional politician, I think I’d know what I would pick. But in any case, you know, history turned out the way it turned out. And one side was proved right and one side was proved wrong. So, it’s not transparency, it’s the issue if by transparency, you mean it’s got to be transparent what people think. In this case, it was perfectly transparent what the different sides to the debate thought. I mean, what went wrong is that some people thought the things that they thought on good grounds and others thought the things that they thought on not very good grounds. And that’s the fundamental point. 0:50:26 SC: Probably, if we were having this discussion in 2004, we would bring up examples like this of intellectual vices and we might even say it seems to be that these intellectual vices are becoming more prevalent in some way, at least in the political realm. And then 15 years later, we’re probably saying, “Oh my god, how naive we were back then.” Now, they’re really being prevalent. Is there any way to be fair about talking about whether or not there is some large scale shift towards putting up with or accepting or even intentionally leaning into this kind of wishful thinking, closed-mindedness sets of vices?  0:51:11 QC: Yeah, so it’s very hard to answer this question without being political. I mean, I would say that things have certainly become more vicious in every sense in the last, in the last 10 or 15 years. So here’s one manifestation of this. It used to be the case, I think, that politicians who would say things that were clearly false and unfounded would be criticized for that and there will be people pointing out that what they were saying was false. And that would make a difference. It wasn’t good for them, politically, to be discovered to be talking nonsense. The thing that seems to have happened recently, is that it seems now that actually making false and unfounded and ridiculous claims is not only politically acceptable, it’s actually politically effective. And it seems as though plenty of voters no longer regard it as a fatal defect in their politicians, that they talk nonsense, say things that are just plainly not… That are plainly not true. 0:52:30 QC: So there’s this great discussion of the notion of bullshit. So, a philosopher called Harry Frankfurt wrote this absolutely brilliant essay about 30 years ago called On Bullshit, where he distinguishes between lying and bullshitting. So the liar says things that he knows are false and he says them in order to deceive other people whereas the bullshitter, Frankfurt says, is someone who just doesn’t care whether the things he says are true or false. They just have no concern with truth at all. And so, I think one way of thinking about what we’ve seen in politics in the last few years has been the increase in bullshit levels in politics, where bullshit is now being almost being used as a kind of technique in politics where you say something without any… You say something about immigration or climate change, or whatever it is, and you say something seemingly with no concern at all about whether what you’re saying is true or justified or well-founded. And as I was saying, I think 20, 30, 40 years ago, that would have got you into some trouble and politicians actually went to some length to try to avoid being caught doing that kind of thing, whereas now, it’s just… It seems to be politically acceptable to bullshit. 0:53:58 QC: And the attitude that underpins bullshit, this attitude of not giving a shit about the truth or the evidence, I mean, that’s… That attitude is an example of an intellectual vice, a very powerful and these days rather common one in the political realm. So I would… So my general take on this is fairly pessimistic. I mean, I think things have been getting worse. Someone wrote a book, actually, in which they talked about something which they called peak bullshit. And I guess the interesting question is, “Have we now reached… Have we reached peak bullshit or is there even more bullshit still to come?” There’s always a temptation to think things couldn’t possibly get any worse. And sometimes they do. 0:54:49 SC: Oh, no. 0:54:49 QC: So, I think we really need to be… We need to be worried. We need to be really concerned about the lowering of the intellectual tone and caliber of political debate. I think that’s a really terribly worrying, worrying thing. And what’s even more worrying than the fact that politicians do it, is the fact that a lot of voters just don’t seem to care. So, that’s a rather downbeat assessment but that’s what I think anyway. 0:55:18 SC: Well, and it’s not just politicians, right? Among the people who are not professional politicians, not only is there a greater acceptance of people who do not seem to be that invested in telling the truth, but I know that you have a new book coming out on conspiracy theories. 0:55:36 QC: Yeah. 0:55:37 SC: Is this… Is there an increase in the acceptance of conspiracy theories? Is that hand-in-hand with the acceptance of bullshit?  0:55:45 QC: Well, and this is a really interesting question. I mean, of course, everyone thinks that conspiracy theories are more popular now than they have ever been, that we’re living in an age of conspiracy. I mean, interestingly, there’s been some research done on this question about, particularly a belief in conspiracy theories in the US and the empirical evidence is that belief in conspiracy theories has actually been going down in the US, not going up. So, there is an issue here about what the actual facts are. I mean, the research showing this is really, really, really good and very kind of ingenious and I think quite, quite convincing. Nevertheless, leaving aside the question of whether conspiracy theories are more or less prevalent, it’s true that conspiracy theories are popular and influential across the world and particularly in the US. And one might wanna think up… One might want to relate the whole issue of belief in conspiracy theories to intellectual vices and maybe there’s something in that. But actually in the book on conspiracy theories, which I’ve just finished and which is coming out soon, I’m actually much more interested in the idea that conspiracy theories or at least the sort of big ticket conspiracy theories are really forms of political propaganda, that what they really do is to advance a political agenda and that’s really their role. 0:57:15 QC: And I think they’re used… Conspiracy theories are used quite sort of self-consciously in that way. If you are… I mean, this is a very contentious example but if you are strongly opposed to gun control in the US and you are confronted by all these terrible mass shootings then, of course, you know it’s gonna be quite tempting to say that these are false flags or that some of these were false flags. And that’s just a way to deflect criticism of gun use. So, that’s an example of how a conspiracy theory is not just a theory. It’s a way to make a political point and to advance a political agenda. And if you think of them that way, it’s not even clear that the people who put these theories forward have necessarily believed them. The thing that people often ask is, well, why do people believe conspiracy theories? And I think it’s worth actually just pausing to reflect on the distinction between the people who invent and promote these theories and consumers of these theories. And I don’t think it’s true that everyone who invents these theories believes them. And I don’t even necessarily think it’s true that consumers of conspiracy theories necessarily believe them either. But it’s all… The fundamental point is that to think about conspiracy theories, you really have to think about their political role, their political function. And then I wanna say that the function of conspiracy theories is they’re fundamentally forms of propaganda. 0:58:47 SC: Okay, good. We’re definitely looking forward to that book. But before we go, I do wanna circle back to this idea or this question of what we personally do about the possibility that we are subject to intellectual vices. Whenever I hear people talk about irrationality and cognitive biases and so forth, you can always see people in the audience going, “Oh yes, my intellectual enemies are subject to all these things.” And it’s much harder to look at ourselves. But happily you’ve written a whole book on self-knowledge. Is there an intersection between the search for better self-knowledge and the guarding ourselves against intellectual vices because probably there aren’t that many people who say, “Oh yeah, I proudly have this particular intellectual vice.” 0:59:37 QC: Yeah, yeah. So, I mean, I think it’s true that to actually do something about your own intellectual vices, you need to recognize that you have them. And most of us are really bad at recognizing our own intellectual vices. I mean, we’re very easy at recognizing the vices of other people but not our own vices. And I… One thing I say in the book is that one explanation for that is that many of our intellectual vices are what I call stealthy vices. They’re vices that actually obstruct or block their own detection. So this is relate… I mean, this is in the same ball park as the famous Dunning-Kruger effect. So, the kind of pop version of the Dunning-Kruger effect is some people are too stupid to know how stupid they are. So that’s a case where the trait itself, stupidity, blocks its own detection by the person who has it, who has that trait. And I think that’s also true of many intellectual vices. And of course, as long as we don’t recognize our own intellectual vices, the whole question of what we’re gonna do about them doesn’t even arise. But although we are reluctant, I think, to recognize our own vices, it isn’t actually an impossible thing to do. And the way that our intellectual vices really come out is when they have terrible consequences and… 1:00:57 QC: And when the consequences make it apparent that we have those vices. Again, having bad consequences isn’t a guarantee that you’ll recognize them because you may have other vices that make you explain it all away in some other way. So, I guess, I wanna say that there is a connection with the whole topic of self-knowledge. It is difficult to get to know our own intellectual vices because many of these vices are stealthy vices, but it’s not impossible to know our own intellectual vices. It is possible, I think, for some of us to actually be honest with ourselves and actually think in a serious way about our own intellectual attitudes and character traits and thinking styles. And just one thing to just point out, if you think of prejudice as an intellectual vice, as well as, I believe, a moral vice, it’s actually not true that people don’t recognize their own prejudices. I’ve seen an opinion survey of people in the UK asking them, “Would you say that you are racially prejudiced?” And something like a quarter or a third of people said yes, in answer to that question. 1:02:17 QC: So it’s actually not true that people don’t recognize their own intellectual vices, they do recognize them. Maybe these people who said that they were prejudiced wouldn’t accept that there’s anything wrong with being prejudiced, but maybe some would. Maybe we should give… Maybe we need to have a more sophisticated view about what truths about themselves, people are willing to recognize, and what truths about themselves they’re not willing to recognize. 1:02:45 SC: Yeah. I guess, I’m thinking mostly about things like wishful thinking because that’s probably, of the vices that you’ve gone through, the one that I can see in myself the most vividly. I think that wishful thinking is bad. I know that I do it, I try not to do it, and yet I do it. Maybe I’m better at avoiding it now than I was when I was younger, but I don’t know, are there exercises one can do? Is it should I be meditating or are there just philosophical brain-stretching exercises that I can train myself to have fewer intellectual vices?  1:03:23 QC: Well, in the case of wishful thinking, a simple question to ask yourself is, is this wishful thinking? Supposing you have a favorite sports team and you’re convinced that they’re gonna win the Super Bowl or whatever it is, I think a perfectly sensible question to ask yourself whenever you make a prediction like that is, is this just wishful thinking? Am I saying this, am I thinking this because it’s really the outcome that I want? Now, maybe you won’t be able to answer that question, maybe you can’t be sure what’s really driving you in this case, but it’s a question that you can certainly raise for yourself on these occasions. And something that I think all of us are able to do is after the event, we’re quite often willing to say, “Well, I guess that was just wishful thinking.” 1:04:11 QC: So it’s not completely beyond us to accept that wishful thinking might be playing a role and also detecting it after the event. I don’t suppose that it’s possible to prevent it altogether. I think wishful thinking is just we are hard-wired to do it to some extent, but there are degrees of it. And I call my view in the book a kind of moderately optimistic view about some vices. What I mean by that is that there is the kind of pessimist who says, “We’re just stuck with these things, there’s just nothing that we can do about them.” And I don’t think that’s plausible. But equally, I also want to accept that tackling our own intellectual vices is difficult, it’s hard, and that it isn’t always possible to do it very effectively. But the choice isn’t between being completely in control and having no control. I think we’re somewhere in the middle. We have some degree of control and it’s a matter of exercising whatever control we have over these personal qualities that are doing us no good. 1:05:29 SC: I probably should’ve ask this earlier, but it brings to mind this question of, is there an intellectual vice of the sort of unequal or biased attention to different things? Like if I see prejudice against my group, I’m hypersensitive to that and if I see prejudice against someone else’s group, I go like, “Hey, you should suck it up and deal with it.” Is there some intellectual vice that qualifies as that?  1:05:54 QC: Yeah. It’s a kind of bias, right? So that would be one way to describe it. This isn’t really an intellectual vice, but something else, that’s a very powerful force. It’s a kind of persecution complex. The idea that [1:06:16] ____ stuff that happens to the in-group is particularly terrible and much worse than anything that happens to other groups. So, I think that would be a case where there are intellectual factors at play, but there are also kind of moral factors, and maybe that’s also something that’s worth thinking about, of how intellectual vices interact with moral vices and whether there’s really a sharp distinction between intellectual and moral failings. And I think that a lot of the intellectual failings that I talk about seem also to be moral failings. Close-mindedness seems to be a moral failing, but then there are other intellectual vices that aren’t. I’m not sure I’d wanna call gullibility a moral failing or foolishness a moral failing. So I think they’re kind of quite subtle. There are quite subtle questions here about how these two things interact. And the example that you just gave is one that just brings out how complicated this is. 1:07:17 SC: Well, it is complicated. I think that if nothing else, the whole discussion probably is a little bit unfair, but it’s kind of depressing to think that all these vices that we’re all subject to, that maybe sunlight is the best disinfectant. If we keep talking about them, people will automatically become a little bit more self-correcting. 1:07:36 QC: Yeah. Hopefully, that’s right. And the other thing that I would urge people to do is not only to reflect on their own intellectual vices, but also just to think about why this topic really matters and think about these big political events and political developments and just think about how these vices have really had a significant impact there. And I think that should really bring home to people that, “Look, this really matters. This isn’t just abstract philosophy, it matters.” 1:08:06 SC: Well, I’ve had a couple of podcast episodes on the nature of democracy and I think maybe you make this point in the book or maybe I just overlaid it on top, but if we live in a democracy, these things matter a lot, we make choices. The power of governing our future as a society and a polity is in our hands. And therefore, it’s kind of our responsibility, not just for our personal lives, but for the rest of the world, to try to be as intellectually virtuous as we can. 1:08:38 QC: Yeah, absolutely. So if you’re thinking about the basis on which you vote for one side or another… For democracy to work well, it’s quite important that voters actually know something about what the policies are of different political parties and take the trouble to find stuff like that out. And maybe one of the things is going wrong at the moment is that people aren’t really interested in that, so much as identity politics, just voting on the basis of, “He’s one of us or not one of us.” And that’s had some pretty dramatic consequences on politics. So I completely agree that you can’t really have a well-functioning democracy along with massive intellectual vices affecting both leaders and the led. That’s just not going to end well. 1:09:38 SC: Yeah, I suspected that these things are never gonna go away, but we can at least keep up the good fight against them. So Quassim Cassam, thanks so much for being on the podcast. 1:09:45 QC: No, it has been my pleasure. Thanks very much. [music]		  I thought this was an excellent podcast, overall, but from 50 minutes on it was truly insightful. I will be buying all of Cassam’s books. I am especially looking forward to his book on conspiracy thinking. Nevertheless, I think conspiracy theories are grounded in religious, cultural, economic and gender issues, although, I suppose you can boil them down to the political. (Cf. Witch trials in 17th century England, Europe, and America.)
Hopefully, all my friends will be able to take advantage of his thoughts on self-analysis…and better themselves. Kelvin R. Throop For anyone interested, I wrote an unpublished ten-page piece on Harry Frankfurt’s Bullshit, referred to most enthusiastically by Prof.Cassam, about twelve years ago, in which I took Franfurt’s idea that bullshit is characterized by an indifference on the part of the speaker (or actor) as to the truth of what is spoken by the speaker (or what action is taken by the actor), shifted the focus of the analysis to the receiver, and found the peculiar frustration attaching to bullshit in the fact that the receiver feels there is no way to effectively counter the unsatisfying reception of something objectionable, even and especially if normative, legal or other standards exist, or are even appealed to or implied by the speaker (or actor) as justification.  If you will forgive me, I will summarize the idea by quoting from the piece: “…we must submit on precisely those occasions when clear-cut rules which we think should more-or-less automatically generate the kinds of objections we hold are clearly those which exist in the wider moral, civic or other kind of community.  But far from being able to appeal to these, we sense we are threatened not to, with anything from implicit ridicule or indifference to out-and-out violence…It is this visceral sense of casually enforced and illegitimate isolation from a community of listeners who, according to their own publicized standards of behavior and communication would seem to an enthusiastic hearing of our objections that seems to characterize bullshit and take it out of the realm of normal discourse and invest it with the kind of desperation that has always been the wellspring of the obscene.”  To me, this notion goes beyond Frankfurt’s much celebrated piece in an essential way, which involves an indispensable social backdrop for the phenomenon, and makes it appear as much more than what remains, to Frankfurt, an essentially individual one.  I also think the conception I am putting forward says much about the Trump-type phenomena we are all surrounded with now, though the appeal to. wider communities is becoming narrow to the point of insignificance for many.   But there it is, I would love to see discussion or criticism if anyone is interested.  I hope you don’t mind Dr. Carroll, my steering of your wonderful program’s content for my own purpose here, but I did think posting this was relevant and might interest some people.  Thank you, Doctor, and please, please keep up the terrific work! Found the concept very interesting. However, Quassim fails to justify “not being open” to new ideas in his counter example of holocaust deniers (I am not one BTW )
This leaves a big question on his work, by downplaying sceptisism where “facts are well established and case is closed” … isn’t this exactly the thought process that the author defines as narrow mindedness? I’m curios how the thinking about vices change in the context of a community.  For example, my tendency for confirmation bias may be a vice for me, but not necessarily a vice for the community. We actually make progress when energized individuals focus on a point of view and present their arguments to a disinterested audience, as is the case in debates, court hearings, and science  journal articles. Sooner or later, all rationality is, well, rationed. We all can, if we choose, work on enlarging the ratio of rationality, and evaluate ourselves as the ‘good enough’ person. To Laurence Peterson, thank you for your summary of Frankfurt’s work. I also found another helpful piece by
Jeet Heer in the New Republic, 12/2015 that was very accessible. Alas, Heer’s thoughts did not prevent Trump
from behaving badly from then on. There seems to be an unfortunate immunity or numbness that just perplexes me. I hope the podcast, Frankfurt’s thoughts, and your’s sink in soon. Thank you, Mr. Trout, for your interest and kind words regarding the Frankfurt piece and commentary.  And thank you again, Sean Carroll, for this wonderful podcast. Wasn’t Kilgore Trout a Vonnegut character???…. The challenge is to recognize an intellectual vice and not succumb to it.  There is nothing new about claiming an intellectual opponent suffers from a mental defect. Trump opponents do it all the time.  You could say it is a de-vice common to political speech.    I have encountered a more modern term for the bullshit artist —  such a person is said to be ‘meta.’   The quality of being meta is seen as advantageous to effective speaking.  The meta-speaker simply says whatever they think (or want) to be true as if it were true. Come to think of it, this really is nothing new is it? Once again, I, for one, believe emphasis must be placed on our propensities (which can and do change, regarding the very same subject matter, based on setting or circumstance) to receive the specific content (speech action or plain action) without comment or further action, even though we are, sometimes highly, unsatisfied with it.  I do not believe that we can account for the peculiar frustration that attaches to the idea of bullshit without bringing this aspect to the fore, which Harry Frankfurt simply did not do, and, which the suggestion of ‘meta’ here, interesting though it is, like Franfurt’s bold postulation, recapitulates. Não existe uma fórmula, é verdade, e, minha opinião, desnecessária! Individualidade!
Concordo que deveremos procurar identificar nossos vícios intelectuais, e, autocorrecao! Não é fácil, mas, acredito, sucesso!
Mente fechada, excesso de confiança-vícios intelectuais! Sem dúvida!
Sensatez, bom senso-virtude intelectual! O que a delimita/define, em variadissimas situações diferenciadas?
Obrigada, Sean Carroll
Obrigada, Quassim Cassam Comments are closed. Sean Carroll hosts conversations with the world's most interesting thinkers. Science, society, philosophy, culture, arts, and ideas.